
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebook.ipynb

import numpy as np
import operator

def get_empty_probs():
    """Word BUY"""
    b_prior_probs = {
        'B1': 0.,
        'B2': 0.,
        'B3': 0.,
        'Bend': 0.,
    }
    b_transition_probs = {
        'B1': {'B1': 0., 'B2': 0., 'B3': 0., 'Bend': 0.},
        'B2': {'B1': 0., 'B2': 0., 'B3': 0., 'Bend': 0.},
        'B3': {'B1': 0., 'B2': 0., 'B3': 0., 'Bend': 0.},
        'Bend': {'B1': 0., 'B2': 0., 'B3': 0., 'Bend': 0.},
    }
    # Parameters for end state is not required
    b_emission_paras = {
        'B1': (0, 0),
        'B2': (0, 0),
        'B3': (0, 0),
        'Bend': (None, None)
    }

    """Word CAR"""
    c_prior_probs = {
        'C1': 0.,
        'C2': 0.,
        'C3': 0.,
        'Cend': 0.,
    }
    c_transition_probs = {
        'C1': {'C1': 0., 'C2': 0., 'C3': 0., 'Cend': 0.},
        'C2': {'C1': 0., 'C2': 0., 'C3': 0., 'Cend': 0.},
        'C3': {'C1': 0., 'C2': 0., 'C3': 0., 'Cend': 0.},
        'Cend': {'C1': 0., 'C2': 0., 'C3': 0., 'Cend': 0.},
    }
    # Parameters for end state is not required
    c_emission_paras = {
        'C1': (None, None),
        'C2': (None, None),
        'C3': (None, None),
        'Cend': (None, None)
    }

    """Word HOUSE"""
    h_prior_probs = {
        'H1': 0.,
        'H2': 0.,
        'H3': 0.,
        'Hend': 0.,
    }
    # Probability of a state changing to another state.
    h_transition_probs = {
        'H1': {'H1': 0., 'H2': 0., 'H3': 0., 'Hend': 0.},
        'H2': {'H1': 0., 'H2': 0., 'H3': 0., 'Hend': 0.},
        'H3': {'H1': 0., 'H2': 0., 'H3': 0., 'Hend': 0.},
        'Hend': {'H1': 0., 'H2': 0., 'H3': 0., 'Hend': 0.},
    }
    # Parameters for end state is not required
    h_emission_paras = {
        'H1': (None, None),
        'H2': (None, None),
        'H3': (None, None),
        'Hend': (None, None)
    }
    return (b_prior_probs, b_transition_probs, b_emission_paras,
            c_prior_probs, c_transition_probs, c_emission_paras,
            h_prior_probs, h_transition_probs, h_emission_paras,)

def part_1_a():
    """Provide probabilities for the word HMMs outlined below.

    Word BUY, CAR, and HOUSE.

    Review Udacity Lesson 8 - Video #29. HMM Training

    Returns:
        tuple() of
        (prior probabilities for all states for word BUY,
         transition probabilities between states for word BUY,
         emission parameters tuple(mean, std) for all states for word BUY,
         prior probabilities for all states for word CAR,
         transition probabilities between states for word CAR,
         emission parameters tuple(mean, std) for all states for word CAR,
         prior probabilities for all states for word HOUSE,
         transition probabilities between states for word HOUSE,
         emission parameters tuple(mean, std) for all states for word HOUSE,)


        Sample Format (not complete):
        (
            {'B1': prob_of_starting_in_B1, 'B2': prob_of_starting_in_B2, ...},

            {'B1': {'B1': prob_of_transition_from_B1_to_B1,
                    'B2': prob_of_transition_from_B1_to_B2,
                    'B3': prob_of_transition_from_B1_to_B3,
                    'Bend': prob_of_transition_from_B1_to_Bend},
             'B2': {...}, ...},

            {'B1': tuple(mean_of_B1, standard_deviation_of_B1),
             'B2': tuple(mean_of_B2, standard_deviation_of_B2), ...},

            {'C1': prob_of_starting_in_C1, 'C2': prob_of_starting_in_C2, ...},
            {'C1': {'C1': prob_of_transition_from_C1_to_C1,
                    'C2': prob_of_transition_from_C1_to_C2,
                    'C3': prob_of_transition_from_C1_to_C3,
                    'Cend': prob_of_transition_from_C1_to_Cend},
             'C2': {...}, ...}
            {'C1': tuple(mean_of_C1, standard_deviation_of_C1),
             'C2': tuple(mean_of_C2, standard_deviation_of_C2), ...}
            {'H1': prob_of_starting_in_H1, 'H2': prob_of_starting_in_H2, ...},
            {'H1': {'H1': prob_of_transition_from_H1_to_H1,
                    'H2': prob_of_transition_from_H1_to_H2,
                    'H3': prob_of_transition_from_H1_to_H3,
                    'Hend': prob_of_transition_from_H1_to_Hend},
             'H2': {...}, ...}
            {'H1': tuple(mean_of_H1, standard_deviation_of_H1),
             'H2': tuple(mean_of_H2, standard_deviation_of_H2), ...}
        )
    """

    buy1 = [36, 44, 52, 56, 49, 44]
    buy1_bounds = [2, 4]

    buy2 = [42, 46, 54, 62, 68, 65, 60, 56]
    buy2_bounds = [3, 6]

    buy3 = [42, 40, 41, 43, 52, 55, 59, 60, 55, 47]
    buy3_bounds = [3, 6]

    car1 = [47, 39, 32, 34, 36, 42, 42, 42, 34, 25]
    car1_bounds = [3, 6]

    car2 = [35, 35, 43, 46, 52, 52, 56, 49, 45]
    car2_bounds = [3, 6]

    car3 = [28, 35, 46, 46, 48, 43, 43, 40]
    car3_bounds = [3, 6]

    house1 = [37, 36, 32, 26, 26, 25, 23, 22, 21, 39, 48, 60, 70, 74, 77]
    house1_bounds = [5, 10]

    house2 = [50, 50, 49, 47, 39, 39, 38, 38, 50, 56, 61, 67, 67, 67, 67]
    house2_bounds = [5, 10]

    house3 = [45, 43, 44, 43, 40, 35, 36, 37, 39, 45, 60, 68, 66, 72, 72, 75]
    house3_bounds = [5, 10]

    b_prior_probs, b_transition_probs, b_emission_paras, c_prior_probs, \
    c_transition_probs, c_emission_paras, h_prior_probs, h_transition_probs, \
    h_emission_paras = get_empty_probs()

    # given a dataset, boundaries and statenum, returns points of data
    def get_region_datapoints(d, b, state):
        regions = b.copy()
        regions.insert(0, 0)
        regions.append(len(d))
        tmp_state_datapoints = d[regions[state]:regions[state + 1]]
        return tmp_state_datapoints

    # First calculate transition probabilities for state
    def __get_trans_probs(data_list, bound_list, num_states):
        probabilities = []
        for i in range(num_states):
            # get first state points across data
            state_num_datapoints = 0
            vals = []
            for j in range(len(data_list)):
                example_datapoints = data_list[j]
                region_bounds = bound_list[j]
                region_datapoints = get_region_datapoints(example_datapoints, region_bounds, i)
                state_num_datapoints += len(region_datapoints)
                vals += region_datapoints

            # Transition prob
            p_trans = 1 / (state_num_datapoints / num_states)
            # Self transition prob
            p_self_trans = 1 - p_trans
            # State average
            average = np.average(vals)
            # Std dev
            std_dev = np.std(vals)

            # transition prob, self-transition prob, average, std_dev
            probabilities.append((p_trans, p_self_trans, average, std_dev))

        return probabilities

    def get_trans_probs(data_list, bound_list):
        num_states = len(bound_list[0]) + 1
        converged = False
        while not converged:

            trans_probs = __get_trans_probs(data_list, bound_list, num_states)
            orig_bounds_hash = hash(str(bound_list))

            for m in range(len(data_list)):  # move boundaries for each example
                curr_data = data_list[m]
                curr_bounds = bound_list[m]
                for n in range(len(curr_data) - 1):  # examine each number
                    bound_left, bound_right = False, False

                    if n in curr_bounds:
                        bound_left = True
                    if n + 1 in curr_bounds:
                        bound_right = True
                    if n == 0 or (bound_left and bound_right):
                        continue

                    curr_val = curr_data[n]
                    if bound_left:
                        # gets the index of the boundary split value.  used to find state.
                        bound_index = curr_bounds.index(n)

                        # index 2 = mean, index 3 = std dev
                        dist_to_left_state = abs(trans_probs[bound_index][2] - curr_val) / trans_probs[bound_index][3]
                        dist_to_curr_state = abs(trans_probs[bound_index + 1][2] - curr_val) / \
                                             trans_probs[bound_index + 1][3]

                        if dist_to_left_state < dist_to_curr_state:
                            curr_bounds[bound_index] += 1

                    elif bound_right:
                        bound_index = curr_bounds.index(n + 1)

                        # index 2 = mean, index 3 = std dev
                        dist_to_right_state = abs(trans_probs[bound_index + 1][2] - curr_val) / \
                                              trans_probs[bound_index + 1][3]
                        dist_to_curr_state = abs(trans_probs[bound_index][2] - curr_val) / trans_probs[bound_index][3]

                        if dist_to_right_state < dist_to_curr_state:
                            curr_bounds[bound_index] -= 1

                bound_list[m] = curr_bounds

            new_bounds_hash = hash(str(bound_list))
            converged = orig_bounds_hash == new_bounds_hash
        return trans_probs

    # get_trans_probs() returns (p_trans, p_self_trans, mean, std)

    # BUY
    data_list = [buy1, buy2, buy3]
    bound_list = [buy1_bounds, buy2_bounds, buy3_bounds]
    results_b = get_trans_probs(data_list, bound_list)

    b_emission_paras['B1'] = (np.round(results_b[0][2], 3), np.round(results_b[0][3], 3))
    b_emission_paras['B2'] = (np.round(results_b[1][2], 3), np.round(results_b[1][3], 3))
    b_emission_paras['B3'] = (np.round(results_b[2][2], 3), np.round(results_b[2][3], 3))
    b_transition_probs['B1'] = \
        {'B1': np.round(results_b[0][1], 3), 'B2': np.round(results_b[0][0], 3), 'B3': 0, 'Bend': 0}
    b_transition_probs['B2'] = \
        {'B1': 0, 'B2': np.round(results_b[1][1], 3), 'B3': np.round(results_b[1][0], 3), 'Bend': 0}
    b_transition_probs['B3'] = \
        {'B1': 0, 'B2': 0, 'B3': np.round(results_b[2][1], 3), 'Bend': np.round(results_b[2][0], 3)}
    b_transition_probs['Bend'] = \
        {'B1': 0, 'B2': 0, 'B3': 0, 'Bend': 1.0}

    # CAR
    data_list = [car1, car2, car3]
    bound_list = [car1_bounds, car2_bounds, car3_bounds]
    results_c = get_trans_probs(data_list, bound_list)

    c_emission_paras['C1'] = (np.round(results_c[0][2], 3), np.round(results_c[0][3], 3))
    c_emission_paras['C2'] = (np.round(results_c[1][2], 3), np.round(results_c[1][3], 3))
    c_emission_paras['C3'] = (np.round(results_c[2][2], 3), np.round(results_c[2][3], 3))
    c_transition_probs['C1'] = \
        {'C1': np.round(results_c[0][1], 3), 'C2': np.round(results_c[0][0], 3), 'C3': 0, 'Cend': 0}
    c_transition_probs['C2'] = \
        {'C1': 0, 'C2': np.round(results_c[1][1], 3), 'C3': np.round(results_c[1][0], 3), 'Cend': 0}
    c_transition_probs['C3'] = \
        {'C1': 0, 'C2': 0, 'C3': np.round(results_c[2][1], 3), 'Cend': np.round(results_c[2][0], 3)}
    c_transition_probs['Cend'] = \
        {'C1': 0, 'C2': 0, 'C3': 0, 'Cend': 1.0}

    # HOUSE
    data_list = [house1, house2, house3]
    bound_list = [house1_bounds, house2_bounds, house3_bounds]
    results_h = get_trans_probs(data_list, bound_list)

    h_emission_paras['H1'] = (np.round(results_h[0][2], 3), np.round(results_h[0][3], 3))
    h_emission_paras['H2'] = (np.round(results_h[1][2], 3), np.round(results_h[1][3], 3))
    h_emission_paras['H3'] = (np.round(results_h[2][2], 3), np.round(results_h[2][3], 3))
    h_transition_probs['H1'] = \
        {'H1': np.round(results_h[0][1], 3), 'H2': np.round(results_h[0][0], 3), 'H3': 0, 'Hend': 0}
    h_transition_probs['H2'] = \
        {'H1': 0, 'H2': np.round(results_h[1][1], 3), 'H3': np.round(results_h[1][0], 3), 'Hend': 0}
    h_transition_probs['H3'] = \
        {'H1': 0, 'H2': 0, 'H3': np.round(results_h[2][1], 3), 'Hend': np.round(results_h[2][0], 3)}
    h_transition_probs['Hend'] = \
        {'H1': 0, 'H2': 0, 'H3': 0, 'Hend': 1.0}

    b_prior_probs = {'B1': 0.333, 'B2': 0, 'B3': 0, 'Bend': 0}
    c_prior_probs = {'C1': 0.333, 'C2': 0, 'C3': 0, 'Cend': 0}
    h_prior_probs = {'H1': 0.333, 'H2': 0, 'H3': 0, 'Hend': 0}
    # b_prior_probs = {'A1': 0.333, 'A2': 0, 'A3': 0, 'Aend': 0}
    # c_prior_probs = {'B1': 0.333, 'B2': 0, 'B3': 0, 'Bend': 0}
    # h_prior_probs = {'C1': 0.333, 'C2': 0, 'C3': 0, 'Cend': 0}

    return (b_prior_probs, b_transition_probs, b_emission_paras,
            c_prior_probs, c_transition_probs, c_emission_paras,
            h_prior_probs, h_transition_probs, h_emission_paras,)

########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################
##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######
################ END OF LOCAL TEST CODE SECTION ######################

def gaussian_prob(x, para_tuple):
    """Compute the probability of a given x value

    Args:
        x (float): observation value
        para_tuple (tuple): contains two elements, (mean, standard deviation)

    Return:
        Probability of seeing a value "x" in a Gaussian distribution.

    Note:
        We simplify the problem so you don't have to take care of integrals.
        Theoretically speaking, the returned value is not a probability of x,
        since the probability of any single value x from a continuous
        distribution should be zero, instead of the number outputed here.
        By definition, the Gaussian percentile of a given value "x"
        is computed based on the "area" under the curve, from left-most to x.
        The proability of getting value "x" is zero bcause a single value "x"
        has zero width, however, the probability of a range of value can be
        computed, for say, from "x - 0.1" to "x + 0.1".

    """
    if list(para_tuple) == [None, None]:
        return 0.0

    mean, std = para_tuple
    gaussian_percentile = (2 * np.pi * std**2)**-0.5 * \
                          np.exp(-(x - mean)**2 / (2 * std**2))
    return gaussian_percentile


def viterbi(evidence_vector,  # O
            states,  # kj
            prior_probs,  # PI
            transition_probs,  # A
            emission_paras  # B
            ):
    """Viterbi Algorithm to calculate the most likely states give the evidence.

    Args:
        evidence_vector (list): List of right hand Y-axis positions (interger).
        states (list): List of all states in a word. No transition between words.
                       example: ['B1', 'B2', 'B3', 'Bend']
        prior_probs (dict): prior distribution for each state.
                            example: {'X1': 0.25,
                                      'X2': 0.25,
                                      'X3': 0.25,
                                      'Xend': 0.25}
        transition_probs (dict): dictionary representing transitions from each
                                 state to every other state.
        emission_paras (dict): parameters of Gaussian distribution
                                from each state.
    Return:
        tuple of
        ( A list of states the most likely explains the evidence,
          probability this state sequence fits the evidence as a float )
    Note:
        You are required to use the function gaussian_prob to compute the
        emission probabilities.
    """
    #          0  1   2    3    4   5   6    7     8   9  10   11
    # states [B1, B2, B3, Bend, C1, C2, C3, Cend, H1, H2, H3, Hend]

    sequence = []  # X
    probability = 0.0

    if not evidence_vector:
        return sequence, probability

    K = len(states)
    T = len(evidence_vector)
    t1 = np.zeros([K, T])
    t2 = np.zeros([K, T], dtype=int)

    # Initialize probabilities
    for i in states:
        p_y0 = gaussian_prob(evidence_vector[0], (emission_paras[i][0], emission_paras[i][1]))
        t1[states.index(i), 0] = prior_probs[i] * p_y0
        # t2[states.index(i), 0] = 0   # already zeroed by numpy initialization

    # Build trellis
    for ind_i, i in enumerate(evidence_vector[1:], start=1):
        p_ks = t1[:, ind_i - 1].tolist()
        for ind_j, j in enumerate(states):

            tmp_ji = []
            for k in range(len(p_ks)):
                tmp_state = states[k]
                p_kj = transition_probs[tmp_state].get(j, 0)
                p_ji = gaussian_prob(i, (emission_paras[j][0], emission_paras[j][1]))
                tmp_p = p_ks[k] * p_kj * p_ji
                tmp_ji.append(tmp_p)

            k_argmax, k_max = max(enumerate(tmp_ji), key=operator.itemgetter(1))
            t1[ind_j, ind_i] = k_max
            t2[ind_j, ind_i] = k_argmax

    z = [None] * T
    x = [None] * T

    # Find best path probability
    p_high_ind = np.argmax(t1[:, -1])
    z[T - 1] = p_high_ind
    x[T - 1] = states[z[T - 1]]

    # Backtrack and reconstruct path
    for i in range(T - 1, 0, -1):
        z[i - 1] = t2[z[i], i]
        x[i - 1] = states[z[i - 1]]

    sequence = x.copy()
    probability = t1[p_high_ind, T-1]

    return sequence, probability

########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################
##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######
################ END OF LOCAL TEST CODE SECTION ######################


def part_2_a():
    """Provide probabilities for the word HMMs outlined below.

    Now, at each time frame you are given with 2 observations (right hand Y
    position & left hand Y position). Use the result you derived in
    part_1_a, accompany with the provided probability for left hand, create
    a tuple of (right-y, left-y) to represent high-dimention transition &
    emission probabilities.
    """

    """Word BUY"""
    b_prior_probs = {
        'B1': 0.333,
        'B2': 0.,
        'B3': 0.,
        'Bend': 0.,
    }
    # example: {'B1': {'B1' : (right-hand Y, left-hand Y), ... }
    # 'B3': {'B1': (0., 0.), 'B2': (0., 0.), 'B3': (0.625, 0.727), 'Bend': (0.375, 0.273), 'C1': (,), 'H1': (,)},
    p_b_end = (round(0.375/3, 3), round(0.273/3, 3))
    b_transition_probs = {
        'B1': {'B1': (0.625, 0.7), 'B2': (0.375, 0.3), 'B3': (0., 0.), 'Bend': (0., 0.)},
        'B2': {'B1': (0., 0.), 'B2': (0.625, 0.05), 'B3': (0.375, 0.95), 'Bend': (0., 0.)},
        'B3': {'B1': (0., 0.), 'B2': (0., 0.), 'B3': (0.625, 0.727),
               'Bend': p_b_end, 'C1': p_b_end, 'H1': p_b_end},
        'Bend': {'B1': (0., 0.), 'B2': (0., 0.), 'B3': (0., 0.), 'Bend': (1.0, 1.0)},
    }
    # example: {'B1': [(right-mean, right-std), (left-mean, left-std)] ...}

    b_emission_paras = {
        'B1': [(41.75, 2.773), (108.2, 17.314)],
        'B2': [(58.625, 5.678), (78.670, 1.886)],
        'B3': [(53.125, 5.418), (64.182, 5.573)],
        'Bend': [(None, None), (None, None)]
    }

    """Word Car"""
    c_prior_probs = {
        'C1': 0.333,
        'C2': 0.,
        'C3': 0.,
        'Cend': 0.,
    }
    # 'C3': {'C1': (0., 0.), 'C2': (0., 0.), 'C3': (0.8, 0.625), 'Cend': (0.2, 0.375)},
    p_c_end = (round(0.2/3, 3), round(0.375/3, 3))
    c_transition_probs = {
        'C1': {'C1': (0.667, 0.7), 'C2': (0.333, 0.3), 'C3': (0., 0.), 'Cend': (0., 0.)},
        'C2': {'C1': (0., 0.), 'C2': (0., 0.625), 'C3': (1.0, 0.375), 'Cend': (0., 0.)},
        'C3': {'C1': (0., 0.), 'C2': (0., 0.), 'C3': (0.8, 0.625), 'Cend': p_c_end, 'B1': p_c_end, 'H1': p_c_end},
        'Cend': {'C1': (0., 0.), 'C2': (0., 0.), 'C3': (0., 0.), 'Cend': (1.0, 1.0)},
    }
    c_emission_paras = {
        'C1': [(35.667, 4.899), (56.3, 10.659)],
        'C2': [(43.667, 1.7), (37.110, 4.306)],
        'C3': [(44.2, 7.341), (50.0, 7.826)],
        'Cend': [(None, None), (None, None)]
    }

    """Word HOUSE"""
    h_prior_probs = {
        'H1': 0.333,
        'H2': 0.,
        'H3': 0.,
        'Hend': 0.,
    }
    # 'H3': {'H1': (0., 0.), 'H2': (0., 0.), 'H3': (0.812, 0.824), 'Hend': (0.188, 0.176), 'B1': (,), 'C1': (,)},
    p_h_end = (round(0.188/3, 3), round(0.176/3, 3))
    h_transition_probs = {
        'H1': {'H1': (0.667, 0.7), 'H2': (0.333, 0.3), 'H3': (0., 0.), 'Hend': (0., 0.)},
        'H2': {'H1': (0., 0.), 'H2': (0.857, 0.842), 'H3': (0.143, 0.158), 'Hend': (0., 0.)},
        'H3': {'H1': (0., 0.), 'H2': (0., 0.), 'H3': (0.812, 0.824), 'Hend': p_h_end, 'B1': p_h_end, 'C1': p_h_end},
        'Hend': {'H1': (0., 0.), 'H2': (0., 0.), 'H3': (0., 0.), 'Hend': (1.0, 1.0)},
    }
    h_emission_paras = {
        'H1': [(45.333, 3.972), (53.6, 7.392)],
        'H2': [(34.952, 8.127), (37.168, 8.875)],
        'H3': [(67.438, 5.733), (74.176, 8.347)],
        'Hend': [(None, None), (None, None)]
    }

    return (b_prior_probs, b_transition_probs, b_emission_paras,
            c_prior_probs, c_transition_probs, c_emission_paras,
            h_prior_probs, h_transition_probs, h_emission_paras,)

########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################
##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######
################ END OF LOCAL TEST CODE SECTION ######################

def multidimensional_viterbi(evidence_vector, states, prior_probs,
                             transition_probs, emission_paras):
    """Decode the most likely word phrases generated by the evidence vector.

    States, prior_probs, transition_probs, and emission_probs will now contain
    all the words from part_2_a.
    """
    sequence = []  # X
    probability = 0.0

    if not evidence_vector:
        return sequence, probability

    K = len(states)
    T = len(evidence_vector)
    t1 = np.zeros([K, T])
    t2 = np.zeros([K, T], dtype=int)

    # Initialize probabilities
    for i in states:
        # right hand emission, right hand vector
        p_y0_R = gaussian_prob(evidence_vector[0][0], (emission_paras[i][0][0], emission_paras[i][0][1]))

        # left hand emission, left hand vector
        p_y0_L = gaussian_prob(evidence_vector[0][1], (emission_paras[i][1][0], emission_paras[i][1][1]))

        t1[states.index(i), 0] = prior_probs[i] * p_y0_R * p_y0_L

        # t2[states.index(i), 0] = 0   # already zeroed by numpy initialization

    # Build trellis
    for ind_i, i in enumerate(evidence_vector[1:], start=1):
        p_ks = t1[:, ind_i - 1].tolist()
        for ind_j, j in enumerate(states):

            tmp_ji = []
            for k in range(len(p_ks)):
                tmp_state = states[k]
                p_kj = transition_probs[tmp_state].get(j, (0, 0))  # has right-left sides???
                p_ji_R = gaussian_prob(i[0], (emission_paras[j][0][0], emission_paras[j][0][1]))
                p_ji_L = gaussian_prob(i[1], (emission_paras[j][1][0], emission_paras[j][1][1]))
                tmp_p = p_ks[k] * p_kj[0] * p_kj[1] * p_ji_R * p_ji_L

                tmp_ji.append(tmp_p)

            k_argmax, k_max = max(enumerate(tmp_ji), key=operator.itemgetter(1))
            t1[ind_j, ind_i] = k_max
            t2[ind_j, ind_i] = k_argmax

    z = [None] * T
    x = [None] * T

    # Find best path probability
    p_high_ind = np.argmax(t1[:, -1])
    z[T - 1] = p_high_ind
    x[T - 1] = states[z[T - 1]]

    # Backtrack and reconstruct path
    for i in range(T - 1, 0, -1):
        z[i - 1] = t2[z[i], i]
        x[i - 1] = states[z[i - 1]]

    sequence = x.copy()
    probability = t1[p_high_ind, T-1]

    return sequence, probability

########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################
##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######
################ END OF LOCAL TEST CODE SECTION ######################

def return_your_name():
    return "dward45"